{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models based on sklearn\n",
    "Referring to  \n",
    "[Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook)  \n",
    "[Official Document](https://scikit-learn.org/stable/user_guide.html)  \n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic sklearn commands "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multiclass classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised learning\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression -- continuous\n",
    "\n",
    "- 判断线性or非线性\n",
    "  - 残差图\n",
    "  - 散点图\n",
    "  - 训练多个模型看准确率\n",
    "- 回归指标  \n",
    "  **损失函数常用 MAE、MSE、RMSE**   \n",
    "  **性能评估指标常用R-square**（R-square就是在用均值预测的标准下衡量模型的预测性能）\n",
    "  - 越接近0越好\n",
    "    - SSE (残差平方和)  $$\\sum{|y_i-\\hat{y_i}|^2}$$\n",
    "    - MAE (平均绝对误差)  $$\\sum{\\frac{|y_i-\\hat{y_i}|}{n}}$$\n",
    "    - MSE (均方误差)  $$\\frac{SSE}{n}=\\sum{\\frac{|y_i-\\hat{y_i}|^2}{n}}$$\n",
    "    - RMSE (均方根误差) $$\\sum{\\sqrt{\\frac{|y_i-\\hat{y_i}|^2}{n}}}$$\n",
    "  - 越接近1越好 \n",
    "    - R-squared (确定系数)\n",
    "      - SSR：预测数据与原始均值的平方和\n",
    "      - SST（残差）：原始数据与原始均值的平方和\n",
    "      - SSE：预测数据与原始数据的平方和\n",
    "    - Adjusted R-squared  (调整R方)  \n",
    "\n",
    "    只要增加了更多的变量，R-squared 要么保持不变，要么增加。  \n",
    "    如果增加更多无意义的变量，Adjusted R-squared 会下降；如果加入的特征值是显著的，则adjusted R-squared也会上升。  \n",
    "    在单变量线性回归中，R-squared和adjusted R-squared是一致的。  \n",
    "\n",
    "    **结论**：如果单变量线性回归，则使用 R-squared评估；多变量，则使用adjusted R-squared。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error , r2_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性\n",
    "[sklearn线性回归 岭回归 lasso回归示例代码](https://zhuanlan.zhihu.com/p/165493873)\n",
    "- 标准线性回归\n",
    "  - 特征之间相互独立 --> or, 多重共线性\n",
    "- 岭回归\n",
    "  - 可以解决特征数>样本量的问题，有效防止过拟合\n",
    "  - 可以处理高度相关的数据，变量间存在共线性（最小二乘回归得到的系数不稳定，方差很大）\n",
    "- lasso回归  \n",
    "    lasso 容易使得部分权重取 0，所以可以用其做 feature selection，lasso 的名字so即为 selection operator。权重为 0 的 feature 对回归问题没有贡献，直接去掉权重为 0 的 feature，模型的输出值不变。（参考[lasso回归和岭回归](https://www.cnblogs.com/wuliytTaotao/p/10837533.html)）  \n",
    "    lasso 更容易使得权重变为 0，而 ridge 更容易使得权重接近 0。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 标准线性回归\n",
    "- 语法：\n",
    "    ```python\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    ```\n",
    "- Parameters:  \n",
    "\n",
    "    **fit_intercept**：有无截距  \n",
    "    **copy_X**：True赋值，False覆写  \n",
    "    **normalize**：是否归一化  \n",
    "    **n_jobs**：default=1，使用CPU数，-1为使用所有CPU  \n",
    "\n",
    "- Attributes:  \n",
    "\n",
    "    **coef_**：如果label有两个，即y值有两列，那么是一个2D的array  \n",
    "    **intercept_**：截距  \n",
    "\n",
    "- Methods:\n",
    "\n",
    "    **fit(X, y, sample_weight)**: 训练模型  \n",
    "    **get_params(X, y, sample_weight)**: 获取参数  \n",
    "    **set_params(para)**: 设置参数  \n",
    "    **predict(X)**：预测数据  \n",
    "    **score(X)**：评估，得到R方  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_square_error:0.98\n",
      "R-squared: 0.90\n",
      "coefficient of the model:-3.06\n",
      "intercept of the model:5.04\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAGFCAYAAACCBut2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4ZElEQVR4nO3de3Rb5Znv8d+OQoBcbEIgRLZcBPQWSjscSqdMUgV76OIcMi0ZVB06JO1AoZS2A7XDJSUNRRYHl57AgN0W1uFWKKtJDmDUCdMVyswwdiMC9EKZTg+kpTA2+JaQEGIn3JIo+/xhS5Ys7a0tW9qSrO9nraxYW6/2fp0uuh89+32fxzBN0xQAAKhqM0o9AQAAUHoEBAAAgIAAAAAQEAAAABEQAAAAERAAAAAREAAAAEkznQw6fPiwBgcHNW/ePBmGUew5AQCAAjBNU/v27VNdXZ1mzLDPATgKCAYHB9XQ0FCQyQEAAHf19fXJ5/PZjnEUEMybNy95wpqamqnPDAAAFN3IyIgaGhqS93E7jgKCxGOCmpoaAgIAACqMk8f9LCoEAAAEBAAAgIAAAACIgAAAAIiAAAAAiIAAAACIgAAAAIiAAAAAiIAAAADIYaXCYonH44rFYhoaGpLX61UgEJDH4ynllAAAqEolCwii0aiam5vV39+fPObz+dTR0aFgMFiqaQEAUJVK8sggGo0qFAqlBQOSNDAwoFAopGg0WoppAQBQtVwPCOLxuJqbm2Wa5uiBI8b+SMljLS0tisfjbk8NAICq5XpAEIvFxjMDR0haN/YnJSjo6+tTLBZze2oAAFQt1wOCoaGhgo4DAABT53pA4PV6CzoOAABMnesBQSAQkM/nk2EYWd83DEMNDQ0KBAIuzwwAgOrlekDg8XjU0dEx+mJCTJAIEtrb26lHAACAi0qy7TAYDKqzs1N1dXVpx30+nzo7O6lDAACAy0pWujgYDGr7S9uTr7c8sUU9PT0EAwAAlEBJexmkPhZYFljGYwIAAEqE5kYAAICAAAAAEBAAAAAREAAAABEQAAAAERAAAAAREAAAABEQAAAAERAAAAAREAAAABEQAAAAERAAAAAREAAAABEQAAAAERAAAAAREAAAABEQAAAAERAAAAAREAAAABEQAAAAERAAAAAREAAAAJU4IDBNs5SXBwAAY0oWELx94G01/qQx+br5ieZSTQUAgKpXsoDgwf94UM8PPZ98ff9/3C8jYqh3b2+ppgQAQNUqWUAw78h5WY+f1HGSrtxypcuzAQCgupUsIFj18VWW7935mztlRAy9tvc1F2cEAED1KllA4JnhUfzGuJY0LLEc4+/wq+UXLe5NCgCAKlXSXQYzjBnaduk2bbt0m+WYjl91yIgYen34dRdnBgBAdSmLOgRLGpYofmNcZ/nOshxzYvuJuvrJq12cFQAA1aMsAgJpNFvw7GXPKvaVmOWYO567Q0bEUP9Iv4szAwBg+iubgCDhMx/4jOI3xnVm3ZmWYxruaNB1/3JdznPF43F1d3dr06ZN6u7uVjweL+RUAQCYNsouIJBGswW/ufw3+uUlv7Qcc9uzt8mIGBoYGcj6fjQald/vV1NTk1auXKmmpib5/X5Fo9FiTRsAgIpVlgFBwrITlyl+Y1ynLzrdcozvDp/W/tvatGPRaFShUEj9/emPFgYGBhQKhQgKAACYwDAdNBQYGRlRbW2thoeHVVNT48a8MnT3dqvpJ022YwauHtAJs0+Q3+8fDwaOGHvz4OhfhmHI5/Opp6dHHo+neBMGAKDE8rl/l3WGIFWjv1GHvntInzjhE5Zj6m+v18UPXZweDKwb+zMWGJimqb6+PsVi1osXAQCoNhUTEEijxYx+//Xf66m/f8pyzIbXN0itkuban2toaKigcwMAoJJVVECQ8Ncn/bUOffeQTj3+VOtB10paZv221+st+LwAAKhUFRkQSKPZghe/+aL+9cv/aj0okHnIMAw1NDQoEMjyJgAAVapiA4KEz578WR367iF99LiP2g/8zmgwIEnt7e0sKAQAIEXFBwTSaLZg+z9s15NfetJ6kCGZYVO3//R2BYNB9yYHAEAFqJhth04dOnxIi+9crFf2vGI5ZpZnlt6/4X0XZwUAgPum5bZDp2bOmKk/X/VnPbHqCcsxB+IHZEQMbd+13cWZAQBQvqZdQJDwPz74P/Tuundtx5x616mquaW8Mx4AALhh2gYEknTUzKNkhk1d+akrLcfsO7BPRsTQn3b/ycWZAQBQXqbdGgIr7x58V7O/N9t2zPyj5mvPt/e4NCMAAIqrqtcQWDn6iKNlhk1d8ckrLMe89d5bMiKGXn7zZRdnlh2tmwEAbqqaDEGqdw6+oznfm2M7ZuGchdp57U6XZpQuGo2qubk5rVujz+dTR0cHWyYBAI6RIchh9hGzZYZNXfbfLrMc88bbb8iIGHp1z6suzozWzQCA0qjKDEGqtw+8rbm32HdCqp9Xr/6r+23HFEI8Hqd1MwCgYMgQ5GHOrDkyw6Yu/ouLLccM7BuQETHU81ZPUecSi8Vo3QwAKImqDwgSHvzbBzVy/YjtmJN/cLJO6jipaHNw2pKZ1s0AgEIjIEgx78h5MsOmVn58peWY3r29MiKGevf2Fvz6Tlsy07oZAFBoBARZbAhu0PD1w7ZjTuo4SR/50UcKet1AICCfz5fsyjgRrZsBAMVCQGCh5sgamWFTF37sQssxL7/5soyIob7hvoJc0+PxqKOjY/TFhJiA1s0AgGIiIMjh4dDD2vvtvbZjPtD+AZ1212kFuV4wGFRnZ6fq6urSjvt8PnV2dlKHAABQFAQEDtQeVSszbCq42Ppm/OKuF2VEDL0+/PqUrxcMBrX9pfFOjFue2KKenh6CAQBA0cws9QQqyWMXPqa33n1Lx64/1nLMie0nSpLMcM7yDrZSHwssCyxLvo7H44rFYhoaGtLChQslSW+88Ya8Xq8CgUDWxwmpn7EbBwCoXgQEeZp/9HyZYVPnbzpf//zyP1uOMyKG/vgPf9RHjivcwsNsJY1TZStvTBlkAIATVV+pcCr2vLtHC9YvyDkun2xB4tt8z0CPLn3lUknS/rX79eTPn1QoFJLd/1yJhYeJtQaJMsgTPzNxHABgeqJSoUu6n+iWETGkHHWCjIihV/a8kvN80WhUfr9fTU1NuvQrl44f/9not/zkjf0IjZc1Tvk58X5LS4sOHDhg+ZnUcXRRBABIBASTFo/Hx2+4P849/kM//NBo8GDBqqmRJP39l/8+e0nj2bIsb3zXXXdRBhkA4BgBwSSl9R3IgxEx9F9v/VfasbTgQkrPAEzSq68669JIGWQAgMSiwkmzvJG2afSb+2rrz57yg1Mkja8tyNrUaIpOOeUUR+MogwwAkMgQTFrajfSgRgOBtrGfhyW15j6HETH02t7XCvotPVHe+Jvf/CZlkAEAjhEQTFJG34GDY3/GGIahhvsb9Od/+LPtefwdfq182bqZUgbrZQhp5Y1nzZpFGWQAgGMEBJOU2ndg4rfw1BvuB4/7oLNth62Sai3eM6SGhgY9+uijGSWNU00sb0wZZACAUwQEU5C44dbX16cdz3bDNcOmXrkqx9bD1bJcP9De3q5QKJRW0vjRzkeTP1uVN6YMMgDACQoTFUC+pYHtth9ms07r9LEPf0xer1dnfPoM1a4fTSXsvGanTvjHEySNFi+aM2tO1s+/feBtzb1lbs5xAIDpJZ/7N7sMCsDj8aixsdHxeDNs6uU3X9ZHfuSsrHFbW1tyfUKdv066JP85liN6LABA+eCRQYl8eMGHnZc0TqmOPDg4WJwJuSy1KuPKlSvV1NQkv9+vaDRa6qkBQFUiICgxM2zqpW++ZD/o6xrfxpgSQ1Rq2WGrqowDAwMKhUIEBQBQAgQEZWDx8Yud70RYOP7yuV89V6wpFY1dVUZ6LABA6RAQlBEzbOr3V/zeftDl4z/u3LmzuBMqgqxVGemxAAAlR0BQZj6x6BPqOrvL0diDcw/mHlRmnFZlpMcCALiLgKAMBQIB+e7zSRvtx33rP7/lzoQKyGnvBHosAIC7CAjKUKIKovFnw3HNgv/Y8R/FnVSBZJR8noAeCwBQGgQEZSqtCmKrpH+yH/+ZBz6Td8GjUkgt+UyPBQAoHwQEZSwYDKq3t1ddXV3auGajo7UFRsTQH3b+wYXZTR49FgCg/FC6uAJ9/+nva+1Ta3OOS2xlLNfSxSPvjiTLMG/5zBad23gumQEAKKB87t9kCCrQ9Z+53lHdAiNi6I+7/+jCjCYn9ea/LLCMYAAASoiAoIKZYVNX/eVVtmMW37k4mR0AAMAKAUGF+8F5P3DeEwEAAAsEBNOEGTZ1+RmX5xxHtgAAkA0BwTRyz+fvcby2YPuu7S7MCABQKQgIpiEzbOrLn/iy7ZhT7zq1IuoWOBWPx9Xd3a1Nmzapu7ub5kgAkCcCgmnqoQsecpwteGXPK5LK56aa7zyi0aj8fr+ampq0cuVKNTU1ye/300YZAPIws9QTQHGZYVNNP2lSd2+35ZgP/fBDkiTffb7xToQaLRTU0dGRLBQUj8cVi8U0NDQkr9erQCBQ8K2C0WhUzc3NtvOYOD4UCmliOY2BgQGFQiEKHQGAQxQmqhKpxYls3SFpePTHRCnhzs5OScrrRp3vnPav3a8nf/5k1pt76jxSrxWPx+X3+9PbKUvSwfHP+Xw+9fT0UOMAQFWiMBEmb7VGeydIMk1Tpmnqa1/7mkKhUFowII1/Cy9Eaj4ej6u5uXk8GDhCyRt84lhLS0va44NYLJYeDKwb+5Pyub6+PsVisSnPDwCmOwKCKrR/7f7cg1olHTP645tvvpnXjXoytj2zLe+b+9DQkKNzOx0HANWMgKBKmWFTC45eYD+oRclsgaSifgvfsWOHo3GpN3ev1+voM07HAUA1IyCoYrvX7NYdtXfkHtgqqdZ+yFS/hS9atMjRuNSbeyAQkM/nS64xmMgwDDU0NCgQCExpbgBQDQgIqtzxxx8/esM/mGPgao1mBixM9Vv40iVLHd/cE9sSH3nkEV1++eWjjy6MzPGS1N7ennVBYblssQSAcsG2wypXX18/+kPb2IHW/D6fWMk/1W/hHo9HHR0dCoVCtjf3zZs3Z+x2WLBggcyZpvZoT/KYz+dTe3u75VbFQu+YAIBKR4agyiXS7kmtDj+4Lve38HwFg0F1dnaqrq4u7bjP50tufcy222HPnj3a89Z4MLDliS3q6emxrVtQzB0TAFCJCAiqXOKbeVqqvlXjGQMbZtjUvZvuzagNMJVUfDAY1PaXxvssJG7uK1asyLktMWFZYJnlY4J8tzYCQLUgIEDym3lapsChr/7xq8meCIUqIZx6M0/c3HPVHJCDDtDULQAAawQEkDQaFPT29qqrq0s//elPddxxx+X1eSNi6Atf/kLRUvGFqCVA3QIAsEZAgCSPx6PGxkbV19dr9+7d+Z9gjUYfNxQhFV+IWgLULQAAawQEyGD5DblNzhYdFiEVn6vmwMSdCZM5B3ULAFQzAgJkyPoNeb3GaxW0OjzRhLoFU0nFJxY/SrLclliIcxRqxwQAVBoCAmQIBAKqq0/f+pdauMgwDDXc36BDNxzKfbJWSbNGf5xqKt5uW+KGDRumfA5aJQOoZgQEyODxeHTrrbdmfW/iN2kz7GB5/3cktaogqXjLbYnnr5jyOQgGAFQzAoIqkbqgb2tsa84FflY32GzfpM2wqcc+/ljOOcy8eabeOfhO1vceefQRx3ULsm1LzFchzgEA0wkBQRWIRqNafOri5Ovl5y3Puz7Ajx/4sbq6uiy/SQeDQUdBwZzvzUnWLdj8+Obk8Uu/cmmybkHqcQCAOwgIprlEqd7BgcG04/nWB7jwf16oxsZG22/SwWBQh244pK6zu3Kez4gYWvXlVRnHBwYGtGpV5nEAQHEREExjGaV6UxSrVG+iloGjtQXXp/xsUYa4UOhuCAD26HY4jaWV6s0itT5AY2Njwa+fCAoSjwhsrdFonYODclSGOB/ZuhvW+eukSwp7nUKIx+OKxWIaGhqS1+tVIBBgfQMAV5AhmMbKpVSvo+2JUkbdgkKw6m44ODj+CMXJIks3FKoXBABMBgHBNJa27/+gRr+BJ76FW40rglgsNlqPoNXB4FY5qjrohF13w9QsxGQWWRYabZkBlBoBwTSWUar3oDILDLlQqjctA+GgrbK+U5jr5uyQmKKUN17aMgMoBwQE01hqqd6J5X3dLNVrmalw4LB5eNLXzedRSClvvLRlBlAOCAimuUSp3vr6+rTjbpbqtcxUtOb+bM33a5wtSkyxNbZVmzZt0s6dO60HHZH5c6luvOWy1gNAdWOXQRUIBoNasWJFXqvXJ35Lnsq35kSmIhQKyTCM9K2F35OjRwRGxNDhGw87amS0/LzlyUcjHo8n77knbrxurfinLTOAckCGoEok6gNcdNFFOQsMTaxsKEmLT108pefrVpmKia/tzLhphmW2wKq64WQCGa/X6+qKf9oyAygHBARIY1XZcHBwcMqL7oLBoHp7e9XV1aWNGzeqq6tLL734UvL9/Wv3OypoNPeWuWmv4/G4rrvuuvEDqbsJxhgzJtxssywslEYfpezevdvVFf+0ZQZQDggIkGRX2TCxTW+qi+6cZCocVTlMEYvF0gOYNcrYTWAeTjnnEZJWZz/XZZddptWrV7u24j9RQfH9999Xa2trxmMB2jIDcAtrCJBU6sqGaddyWOVw7i1ztfHDGwt23Xg8nrniX0rWbyjkv4FlBcUxW57YonMbzyUzAMAVZAiQVI6r3Z1kC1a+vLIoVQ7tTPXfwEkFRdoyA3ATAQGSMuoFrHcwzgVm2NThGydfj8AwDNXV1+Uc09DQ4Phb/1T+DZxWUKQQEQA3ERAgKWu9gBSlXO1uGEbeawsSTNPUrbfemnKyiScf/au9vV2NjY1FX/HvtILitme2TfoaAJAvAgIk2VU2TL1pljKNPdlsweHD459Z5F2U9p63zptcuOfGin+njxt27Ngx6WsAQL4ICJDGrl5Auax2d5wtWKdkNcTVLePbCn7329+lDXv+N8+n/V6Jf4O6uvTHDIVa8e/0ccOiRYtyDwKAAiEgQIZEvYAtT2xJHnvpxZfKIhhIZYZNNe9tzj2wVdq9e3fy5cRv99m+7QeDQW1/aXvy9ZYntqinp6cg/wa5ChElLF2ydMrXAgCnCAiQlcfj0bLAsrTX5SYej2vjho3O2ipPYhdC6u9cyBX/do8lUl9ve2abNm3apO7ubhYYAig6AgKUVOqNbmtsa143vlgspl27do2+cNg9cbISBYSc3KCdjLV6LJH6qGb5ecsdl03OZ34AkA0BAUpmYs+E5ectz6tfwGRrAZzwjyfk/ZnFpy521Ncgnx4I2R5L3HLLLVmvb1c22c2+CwCmLwIClIRVz4R8+gVk1E1ok2XthKlyMk+rYkN2v1PqY4ilS5bq+uuvH3/TQdnkyVwTALIhIIDr7Hom5NMvIGvdhNTaCQ6DA6uMQcb1bW7QdsWGTNOUaZpqbm62/Z22PbPNtidDatnkxPzsrpk6PwDIhYAArsunZ4Id27oJeTIiRsZz+K2xreMDshQQSp2nk2JD/f39amuzXuzgtO5A4lFJrms6/XcEAInmRiiBQvZMSCzOm9gkSJLuf+B+Xbb9Msfzmnnz2H8OraN/zV84X/pmYeaZEA6Hddppp2Xdvui07kDiUUk59p4AULnIEMB1WZ/9j3UTtBxnI1E3oaurS/fdf1/y+Pxj5meMHbx6MONYhtbRv9566y1H1/d6vdZzTe1TMMYqjb90yVLbngsTyyY7/fdxu/cEgMpEQADX5Xr2P5l+AR6PR3v27NGNN96YPBa8IPNbeM2RNc6qHLYqZ+2C1HkmfqcME9YBSLJM43s8nvSeCxOuJaWXTc5V4KiUvScAVB4CArjO7tn/ZPsFWO1asGKGTfU29zo+/0QT55lWbMgBqzT+ivNXZD2erWyyG30XAFQPAgKUhFXPhMn0C7DbtWDnuNnHOR+8Jv1ltnkGg0FFIhFHp8snjW9XNrnYfRcAVA8CApRM6rP/jRs3qqura1L9AnLtWrCS9hz/Tuefs7tBr1u3Lq91AE7kKptczL4LAKoHAQFKyuPxqLGxURdddJEaGxsnld7OZxX95sc3J3/e9sy28Tfedn695U8vt5xnvusACqVYfRcAVA8CAlQ8p7sWJGnVqlXJ6n2W+/4dZAuMiHXdg3zWAQBAuSAgQMXLWbFwgsS2v+OPP378YGogsUuOOigaEcM2MEhFGh9AuSMggKWpdCJ0U14r/M3RbX9tbW362te+lv7exO2PEUOLOnMXC3ISFJDGB1DuCAiQ1VQ7Ebotsdr+2GOPdTQ+HA5raNB67UEi23Bn5E5HdQvyyRZMBu2NARQbAQEyFKITYSkEg0E98sgj4wem0AGxvr4+7Xm/GTb1whUv5PxcMYKCzY9vpr0xgKIjIECaQnUiLJXGxsb0ioE51hNYefDBBzOe95++6HRH2YK5t8zNOHbNNdeovb1dBw4cyHsuq1ator0xgKIjIECaQnUiLJV8KwZaeeONNyzfM8Omtl26zfL9bO6++26tXr1as2fP1po1a3J/IO2CY3/T3hhAEREQIM106KAXDAbV0tKSe+AUGistaVjirCfCBPF4XLfeemv+QQHtjQEUGQEB0hS6E2GprFiRUgvArjbBFBsr7V+739mEJjRKuv322yf1+CCbcg7OAFQOAgKkKUYnwlLItzaB5EJDoFYl6xvE43HdddddBTltuQdnACoDAQHSFKMTYSk4+T0WLFiQdnyyjZUStnxmix4JPWIzekzr6F+vvvqq4+tYqYTgDEBlICBAhkJ2Iiwlu9/jscce086dO6fUWClbrYaWz7U4+3Cr9KPjfuT4Wol1AxPddtttisVieuRRB4EIANgwTAc9Y0dGRlRbW6vh4WHV1NS4MS+UgXg8rlgspqGhIXm9XgUCgbLPDGRTjN8jUavBnGmOrw9ok2RI+k5ikKQ8YqfEeoSMbYvrld5+OWUtxHHHHafdu3ePLzqUtOFjG7QytNL5hQFMW/ncv2e6NCdUoEQnwkpX6N/DrlaDUg9tV9q6gWLYvXt3xrFVq1bpqBlHVUwmB0B54JEBkKdctRoSvvCFL4xmIlolbc41OntBI0mWjwvS3p8whvoEAPJFQADkyek2v7/53N/onXfe0R133KErl16pO2rvyPkZy6DASuJRQeojhbEGTtQnAJAPHhkAecpaqyHxc8o39UWLFmnWrFlpRZJa1KL259q1+snVRZ8n9QkA5IMMAZAnpzUOli5ZmvXzLWe1TKrKYb6oTwAgHwQEQJ7sahzISB9nxwybuqnxptwXzDeZYFCfAED+CAiASbCqcTDxdS7fPfu7eWcL6n316aWZsyj34lHxeFzd3d3atGmTuru7WQAJlAECAmCSgsGgent704obvfTiS3mfJxqNqu7BOsfjb7nlFj3++OOW7zc3N5f1lsNoNCq/36+mpiatXLlSTU1N8vv9tHIGSozCREABvX3g7eROgf1r92vOrDm247MWOHKqVdJspe8wkFT/k3q99ufXyjJDkPx9J/zfTuLRSyVVwgQqQT73bzIEQAGlpr63xrbapsItCxy1Sfqdg4u1KiMYkKSB/oGibTmcSqo/4/dNqZ+QOEb9BKB0CAiAAsnW28AuFW5b4OhxTanCYTG2HE411Z/2+ybqJ6xTWlBA/QSgdAgIgAJIpMIHBwbTjg8MDCgUCmW9aTq6abflHpJNobccJn6/iQGM3e83kdMghfoJQGkQEABTZNfbwC4VnrXAUUrjosmq99UXdMthoVL9ToMU6icApUFAAExRrt4GVqlwpwWOktok9eSez8DFAwVdUOg01d/a2mq7riDj953AMAzqJwAlREAATNFkU+G2BY6s/ESO1hYYEUNGxOE5c3D6+918881qamrSokWL9Oijj0pKX4QYi8V0++23j01wwnzHfv9yr58ATGf0MgCmyLa3gdW4MYkCR83NzdmzDFbna5Uavt+gvvf6bOdmRIwpl0nON4W/e/duXXjhhVqxYoWef/75tN/L5/Pp2muv1YZHN2hQg2nH29vb2XIIlBB1CIApisfj8vv9GhgYyLqOwDAM+Xw+9fT0WH77jcfjisViGhoa0sKFC3XJJZfkPN//+9P/U+36WsfztAoMUq/t9XoVCATS5pn2+6XWS0hd75Bo6pRj/UMiE/DQ/31IX97+ZUnSls9s0bmN55IZAIqAOgSAi+xS/05T4R6PR42Njbrooot0zjnnODpfqoVHLsw5z2yPEJxsJUz9/Sam+iWlryuYbfH+hEWI119/ffLtZYFlBANAGSAgAArAqreBz+ebVPW9XOeTlFbz4I0b35DvPl/O86auLchnK2FiPnV1OUosr1FaC2irRYgD/QM555pA3wPAHTwyAAooV/q9EOfbvHlzZrnjNsk4NHqjn3PTHO2P7895bt99vvTdA1Iy5W/1mOOt/W/p2H88NnlNHdT4TT9h4qMEq0cMY8ftSjxHo9GM9RU+n08dHR2sNwAcyOf+zaJCoIASqf9inS9XzQPDMDT/nvna27NXM2+2/8+7/6tjN9k2Zdy0U7dKJq4fjUZ11TVXSZdM9bdyxqrvQSKDQd8DoLB4ZABUkHxqHjjeXWDTVCmx5dCqEuNkGIahel/2NtGJxwMbNmzQFVdcQd8DwEUEBEAFybfmgRk2tX9t7scHVrxer21WIl+JRZHr16/PeC91geOXvvQl7d69e/QN+h4AriAgACqI03LHky7/m5It8Hg82rVrV2alwoQjZKmhoUHXXXed6urTFyEmFkWuOH9F2nGrBY655AqQWJAIOEdAAFSQXOWOc5X/dZQtaJV0zejN9Itf/KI2b96c1xy3PLFFPT09Wr9+vba/tD3j+MTn/na9EnKxC3ym2p0RqDYEBEAFKUTNA0drC+YpWSJ5w4YNec0xta5A6jys6g1se2abba+EbHIFPpPpzkg2AdWOgACoMIWoeWCGTUeBgRk2tevCXTruuOOs+y1MsWXCjh078hqfK/CZTHdGsgkAAQFQkYLBoHp7e9XV1aWNGzeqq6srazo+l40f3ph70PHS7ivHFvhZNCWaikWLFuU1Plfg47Q7Y2JB4mSyCcB0RB0CoEIVouaB1+uVVo69aLUfa4ZNzdw5U4d0KHnM5/Pp+7d/X6teXDXpOSxdslQ+n2+0V4KyZC1SYo4tT+Tue5DPToys2QQpWYvBMAy1tLRoxYoVlFfGtEeGAKhiaYsUW3OPP3TCeDAQ/VlUPT09GTsG8mXXK2FiBsJJ3wOnOyy8Xm/e2QRgOiMgAKpYxiLFthwfSHHnjjsL9q3ZqleCz+fLe1Fjxk6MCVIXJOZb1wGYzggIgCpntUgxl6d6nsraQdHKI48+Yrt6PxgMZt2mmG8GwknGIbEgMZ9sAjDdERAA01zqDXhrbGvWG3JikeKWJ7Ykjw2vGXa0E2HuLXMt39v8+HgNg0u/cqmampq0aNEiffvb306bX2K737ZntiWPT6Utsl3GIXVBYj7ZBGC6IyAAprFoNJrWJnn5ecstt9N5PB4tCyxLey05rFtgce1VqzIXG+7evVt33nln8vVJJ52U3O63/Lzlk7pWNlYZh9TdCflkE4DpjoAAmKasGhJNZjtdPv0Qrn7y6uTq/bRNAxaFhvbs2ZP1eGp2YbKcFEZymk0ApjsCAmAaytUmWSpet8B7fnePZt48M7MvwRqNFwmaGBxkObZmzRrXqgU6ySYA0x0BATAN5dMmOV87r9npbGCrpMYJxxJb+9ZkOTahXPFA/4Cr2/2cZBOA6YyAAJiGymY73dKpfZztfoB7qFQITENZ2yQnfrYaNwn71+7XnFlz8tp+mA+2+wHuIUMATENTbZOcL8c7EdbkHpJQ76tnux/gIgICYBqabJtkq5oFqcdTawWkctpB0an169fzHB9wEQEBME3l2ybZqmbBmjVr0o4HL7BfeV+ooGCqPRIA5Ic1BMA0FgwGtWLFCsViMQ0NDcnr9SoQCGR8807ULDBnpt/M+/v7deutt1rWENj8+GatDK3MOJ4IChytLfjI+I8tV7eoXe2SxisY9gz05D4HgCkjQwBMc4k2yRdddJEaGxuzPiawqlmQS65aAY99/LHcJ0lJBKRWSlx86mI1NTXp0q9cmjxWiGJFALIjIACqXK6aBXbsagUksg75dFB8b9F7yZ8nVliUpFWrVuVVYRGAcwQEQJWb6l7/bJ+fbNZh5c8mPH7IUsGwWBUWgWrHGgKgyjmqWZB63O7zYyyzDm1j52p1MDG/pIm9kUwlKyw2NjY6OAkAp8gQAFUuV82CpCzHrWoF5Mw6tDqYWGajxJznT22l3N3dTSYByAMBAVDl7GoW5HLJxZdkPZ4165DIDiS0Sl1nd+V1vaznHxONRuX3+5OtlJuamtK2SwKwR0AAwLJmQUNDg6677jr5fL6sn2tra5Pf789Y6JdPpcS86hYYo3NasmRJWiags7NToVAo4zHF4OD4wsTUQksAMhmmg1U/IyMjqq2t1fDwsGpqatyYF4ASiMfjWWsWxONxtbW1KRwOj3cnlKQ2yTg0etOfWOwouctASltcmAgSshVHclK34LJ3LtOTG59Mu/kn5ihpfBHiQWXM1XeCTx0dHVnbGr994G3NvWWupPEeDU7+bYByls/9mwwBgCS7mgX33ntv1s8kbvYTV//nWylRclbl8P7Z96v/q+mZgLRgIEsr5YSBgQGFQqG8ty5mexyRLTMCVDICAgA55apVYJpmcvV/qmAwqN7eXnV1dWnjxo3q6upST09P1mAgeS6nPRFaJR3n8BdImaeU39bFRKZj4u8/2eACKFdsOwSQk9NaBdnGJbIO+TLDZu5HCFeO/d1q8f4RE34+mB685JpXRj2FlMcRpmnKMAy1tLRoxYrRcos8UkAlIyAAkJOjWgUTxxWA454IrZJuk/S+83M7CXK6u7vHMwMT1iOkBhdtbW26995707IIPp/1egWgHPHIAEBO+ewaKAZHjxCu1fgN24FcwUs0GtWFF17o6FzhcJhHCqh4BAQAcrKrVZB43d7eXtQU+aEbDsl3X/btj/lwErxsfnyzQqGQ9uzZk9/JU0otT2a9AlBKBAQAHJnMroFCSgQljloqS1mzBU6Dl+uuuy593YBF++c0WXY4WC22BMoRAQEAxyaza6DQ1+/s7FTdg3XOPrAm/aXT4CXZaTHHNkanptpACnADiwoB5GWyuwYKJRgM6rPnfVa162vz+lz0Z1Gdf875BXussWDBAn3rW98aLdaUQ6EXWwLFQIYAQMVJvanvvGano88Enw3qoJmta9PkPPzww1q3bl36YssJir3YEigkAgIAVePotqMdrUGoq6+zbfRU76tPVnJMLLbUhOFuLbYECoWAAEDVMSKGDsQPWL5/6623jg3M/v769euTN/nkuoa69HUNbi22BAqFgADA9NOWe8iRNx9pmS1Ycf6KrDf51PdTBYNBbX9pe/L1lie2uLrYEigEAgIAFe3nW36e9bgRMaRbc3/eiBg6dPhQxvGJN/noz+wLDKU+FlgWWMZjAlQcAgIAFW3duuzlCU3TlBwUOJSkI/7XEcnWx6lSb+pLlyyd1PyASkFAAKCi7Rjc4Wzgeufn3BrbSnVBVB0CAgDVo9XZsOVPL5ff79fmxzcXdToJ8Xhc3d3d2rRpk7q7uwlGUBIEBACml/XK6MKYplWOAoP+r/Zr1apVBZmSnWg0Kr/fr6amJq1cuVJNTU3y+/00RYLrCAgAVLRFdYvSDzisPbTxwxtzD/pO/vPJRzQaVSgUolMiygIBAYCK1tZms8fwoMXPGi0n3HV2l+PHCE9vezrfqdmKx+Nqbm7O2kSJTokoBQICABXtc8s/l/dnFixYoEAgMN50qDX3Z77w3Bfyvo6dWCw2nhmgUyLKAAEBgGnlvvvvU01NjaOxaU2HWuWooJEk/dPmf8p3WhmcdkCkUyLcQkAAoOKkptG3PbMt7b26ujqNjIzYfv7NN99ULBZTIBBIb050UI6yBV966UuOeiLYcdoBkU6JcAsBAYCKEo1GtfjUxcnXwQvSywPv2OGsLsHQ0FBac6K0ZkatchQYTCUoyAhGJp6bTolwGQEBgIqRWJU/ODBoOWbRopRdBwc1+higTVkXFUrjzYnq6+szT+bgEYIRMSYVGNApEeWGgABARchYlW/hrE+flfkYICUYyPbNOxgMqre3V11dXbrhhhvGB6cGFDlkK32cC50SUU4ICABUhLRV+Tae+9Vz2R8DyP6bt8fjUWNjo1pbW7MHFK1T/Q2yo1MiygUBAYCK4HS1/Y4dOywfAzj55m25rkBjawYiueeQb7aATokoBwQEACpC2mp7m7UBxx9/vKT0xwAbN25UV1eX42/edgHFY52PyQznbqNoRAyddtdpOccB5cIwcz2QkzQyMqLa2loNDw873t8LAIUUj8fl9/s1MDCQvo4gUdRnjPcBr350+48KknKPx+OKxWIaGhqS1+tVIBBI+/ZumqZm3JT7e1WuAOLtA28nswr71+7XnFlzpjZxYEw+928yBAAqgl0qP9XQ0FDB+gAk1hVcdNFFamxszEjlG4bhOFtw5j1nTnk+QDEREACoGLZbBBPG7s9u9gEww6biN9pf6/mh56dczAgoJgICABUlGAzqwQcftB1Tij4AM4wZjrMFS3+81IUZAfkhIABQcd544w1H4zZv3lzkmWRyki14pu8ZsgUoOwQEACpOxo6D9dnHbdiwoSTtg/PJFnz2oc+6MCMgNwICABUnEAgktxdKyth6mLBr166Stg82w6YOffeQ7Zinep6aVJVDoNAICABUHI/Ho1WrVjkaW+r2wZ4ZHkfZAqDUCAgAVKQVK1aMv3DQxKjUzLCpg9+1SGWkIFuAUiEgAFCREu2Dkxw0MSq1mTNmOl5bsPmP7i+IRHUjIABQkRKFigzDyKuJUTkww6b2fnuv7Zi/ffhv2YkAVxEQAKhYU2liVGozZ8x0NM6IGPr5yz8v8mwAehkAmAZy9RwoR6n9CwZXD6rujrqcn2FxIvKVz/3bWYgKAGUs0XOgUnlmOAtejIihLSu36LwPnVfkGaEa8cgAAEogtWDStme2JX/OtbZg+cblrC1AURAQAIDLotGoFp+6OPk6eMH4WofEToRvnPkN23MYEUP/+uq/Fm2OqD4EBADgomg0qlAopMGBwazvb358dLvhXX9zV866Bef+9FyyBSgYAgIAcEk8Hldzc7Ps1nKvWbMm+TghkS24/IzLbc9rRAz9e8+/F3SuqD4EBADgklgspv7+ftsxA/0DGf0X7vn8PTpwwwHbz53z0DlkCzAlBAQA4BKnfRWyjTvCc4TMsKlLTr/E9rNGxNAve385memhyhEQAIBLMto2T6L/wgMrHtD7N7xve53GnzSSLUDeCAgAwCWJ/gvJUssT+i9IUr2vPmf/hVmeWTLDplZ+fKXtOCNi6OnXn57CjFFNCAgAwCWJ/guSMvovJFxy8SWOz7chuEHvrXvPdkzggQDZAjhCQAAALrLqv5DQ1tYmv9+vaDTq6HxHzjxSZtjUhR+70HacETH0bN+zec8X1YOAAABcFgwG1dvbq0gkkvX9gYEBhUIhx0GBJD0celjvrnvXdsySHy8hWwBLBAQAUCL33ntv1uOJOgUtLS1pJY5zOWrmUTLDpi746AW244yIoV8P/Nr5RFEVCAgAoARy1SQwTVN9fX0ZNQmciH4xqne+847tmE/f92myBUhDQAAAJTCVmgROHH3E0TLDpj734c/ZjjMihp4ffH5S18D0QvtjACiBrDUJEj9bjZuEf77on/XOwXc053tzLMecee+ZkiQzbF1SGdMfGQIAKIFcNQkMw1BDQ0POmgROzD5itsywqf9+yn+3HWdEDL0w9MKUr4fKREAAACVgV5Mg8bq9vV0ej6dg1/zFl36hfWv32Y45454zWFtQpQgIAKBErGoS+Hw+dXZ2KhgMFvyac2fNlRk21eRvsh1nRAz9587/LPj1Ub4M064P55iRkRHV1tZqeHhYNTU1bswLAKpGPB5XLBbT0NCQvF6vAoFAQTMDVva9v08138/9/+msLahc+dy/CQgAoMote2CZYq/bb2985apXdMqxp7g0IxRKPvdvHhkAQJXb+pWtGr5+2HbMB3/4Qflu97k0I5QCAQEAQDVH1sgMm/p0/actxwzsG5ARMdTzVo+LM4NbCAgAAEnPffU59a+2rqAoSSf/4GSd3HGySzOCWwgIAABpjjnqmJxjevb2yIgYem3va8WfEFxBQAAAsDR49aDt+/4Ovz76o4+6NBsUEwEBAMBSYm3BhR+70HLMn978k4yIob7hPhdnhkIjIAAA5PRw6GHt/fZe2zEfaP+ATrvrNHcmhIIjIAAAOFJ7VK3MsKkLPnqB5ZgXd70oI2Kof8R+YSLKDwEBACAv0S9GtWfNHtsxDXc06Iy7z3BpRigEAgIAQN7mHz1fZtjU5z/8ecsxL+x4QUbE0OA++4WJKA8EBACASXv8osf15po3bcfU316vT937KZdmhMkiIAAATMmxRx8rM2zqvA+eZznmt4O/lRExtGP/DhdnhnwQEAAACmLLqi3afd1u2zHef/Rqyf1LXJoR8kFAAAAomAWzF8gMmzrnpHMsxzzb/6yMiKE33n7DxZkhFwICAEDB/dvf/5veuNb+hn/CbSeo6SdNLs0IuRAQAACK4vg5x8sMmzr7xLMtx3T3dsuIGNr19i4XZ4ZsCAgAAEXVfUm3dl6703bMwtsW6rMPfdalGSEbAgIAQNEtnLNQZtjUX/n+ynLMUz1PyYgY2v2O/cJEFAcBAQAgTTweT/68NbY17fVUPXPZMxq6Zsh2zPG3Hq/zNlhvYURxEBAAAJKi0agWn7o4+Xr5ecvl9/sVjUYLdo1FcxfJDJv6VJ11saJfvPILGRFDe961L5GMwiEgAABIGg0GQqGQBgfSSw0PDAwoFAoVNCiQpF9f/msNXD1gO2bB+gVa8X9XFPS6yI6AAACgeDyu5uZmmaaZ8V7iWEtLS0EfH0hS3bw6mWFTpy863XLM4396XEbE0N739hb02khHQAAAUCwWU3+/dcti0zTV19enWCxWlOu/cMUL6lvdZztm/v+er+DDwaJcHwQEAABJQ0P2C/3yHTcZvhqfzLCpU48/1XLMz/74MxkRQ8PvDRdtHtWKgAAAIK/XO/7ioKS2sT8HbcYVyYvffFGvtbxmO+aY/32M/q7z74o+l2pimNkeGE0wMjKi2tpaDQ8Pq6amxo15AQBcFI/H5ff7NTAwkHUdgWEY8vl86unpkcfjcW1eH/nRR/Tymy/bjhm+flg1R3Jvyiaf+zcZAgCAPB6POjo6JI3e/FMlXre3t7saDEjSn678k3qbe23H1H6/Vquiq9yZ0DRGQAAAkCQFg0F1dnaqvr4+7bjP51NnZ6eCwdIs6DvxmBNlhk2ddMxJlmM2/mGjjIihfe/vc3Fm0wuPDAAAaeLxuGKxmIaGhuT1ehUIBFzPDFjpeatHJ//gZNsxF//FxXrwbx90Z0JlLp/7NwEBAKDiNNzRoP4R622SkrRv7T7NnTXXpRmVJ9YQAACmtb7VfXrlqldsx8y7ZZ6++vhXXZpR5SMgAABUpFOOPUVm2NTCOQstx9z/wv0yIobeOfiOizOrTAQEAICKtvPanXr5SvutiXO+N0df//nXXZpRZSIgAABUvA8t+JDMsKn5R823HHP383fLiBh69+C7Ls6schAQAACmjT3f3qPt/7Dddszs783WlVuudGlGlYOAAAAwrXz0uI/KDJu2Owzu/M2dMiKG3jv0noszK28EBACAaWnf2n168Zsv2o45uu1otfyixZ0JlTnqEAAApr2jbj5K78fftx3z7rp3ddTMo1yakTuoQwAAQIr3bnhPf/jGH2zHHN12tK77l+tcmlH5IUMAAKgqMyIzZMr+1vfeuvd05MwjXZpR8ZAhAADAwuHwYf3+67+3HXNU21Fa+29rXZpReSBDAACoWkbEyDnmXwL/ot07d5ddoycnyBAAAOCAGTb1whUv2I45N3auVt67Uk1NTfL7/YpGoy7Nzl0EBACAqnb6otNlhnMky8+W9F2pf7BfoVBoWgYFBAQAAGg0W/Dby39rPcAj6UbJPNFUS0uL4vG4a3NzAwEBAABjPln3SXWd3WU/6BKpb3mffrn1l67MyS0EBAAApBgaGpJaJd1jM8grnbP1HG19batLsyo+AgIAAFJ4vd7RHwY1Ghg8az327AfP1ifv+aQOm4ddmFlxERAAAJAiEAjI5/PJMMa2JD4p6Xbr8b8b+p08N3n09OtPuzK/YiEgAAAghcfjUUdHhySNBwUjypktCDwQ0Kfv+3TFZgsICAAAmCAYDKqzs1P19fVpxxteatDdH7nb8nO/Hvi1PDd59EzfM8WeYsFRqRAAAAvxeFyxWExDQ0MZlQqbn2jWD379A8vPLmlYoqe/8vR4lqEE8rl/ExAAADBJr+19Tf4Ov+2YZy97Vmf5znJnQhNQuhgAABeceMyJMsOmrvzUlZZj/ur+v1LggYAcfP8uKQICAACm6IfLf6j/+tZ/Wb7/9OtPa8ZNM/Sr/l+5OKv8EBAAAFAAJ80/SWbY1DfO/IblmLPuP0tNP2kqy2wBAQEAAAV019/cpVe/9arl+9293Zpx0wz9ZuA3Ls4qNwICAAAK7OT5J8sMm/raGV+zHPOX9/2lznnonLLJFhAQAABQJHd//m69ctUrlu//e8+/a8ZNM/T84PMuzio7AgIAAIrolGNPkRk2ddl/u8xyzJn3nqnl/2d5SVsqExAAAOCC+86/T3++6s+W7z+x8wl5/9KraDTq4qzGERAAAOCSDx77QZlhU43HNGZ9f9esXQqFQiUJCggIAABwUTwe1yu3vSL9cMIbhySNbU5oaWlx/fEBAQEAAC6KxWLq7++X3pTUlvLG/ZJ2SaZpqq+vT7FYzNV5ERAAAOCioaGh7G/sdjiuSGa6ejUAAKqc1+sdf3FQ41mCgzbjXECGAAAAFwUCAfl8vvG2yAeVFgwYhqGGhgYFAgFX50VAAACAizwejzo6OiRpPCgYk3jd3t4uj8fj6rwICAAAcFkwGFRnZ6fq6+vTjvt8PnV2dioYDLo+J8N0UER5ZGREtbW1Gh4eVk1NjRvzAgBg2ovH44rFYhoaGpLX61UgEChoZiCf+zeLCgEAKBGPx6PGxsZST0MSjwwAAIAICAAAgAgIAACACAgAAIAICAAAgAgIAACACAgAAIAICAAAgAgIAACAHFYqTFQ3HhkZKepkAABA4STu2w66FDgLCPbt2ydJamhomMK0AABAKezbt0+1tbW2Yxw1Nzp8+LAGBwc1b968jFaNAACgPJmmqX379qmurk4zZtivEnAUEAAAgOmNRYUAAICAAAAAEBAAAAAREAAAABEQAAAAERAAAAAREAAAAEn/H9TaLaSryiGOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# simple linear regression 一元\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 定义样本和特征数量\n",
    "num_sample=1000\n",
    "num_feature = 1\n",
    "# num_feature = 2\n",
    "\n",
    "# 生成一些样本和特征\n",
    "ideal_coef = -3\n",
    "# ideal_coef = [2,-3]\n",
    "ideal_intercept = 5\n",
    "feature=np.random.normal(size=(num_sample,num_feature))\n",
    "label=ideal_coef*feature + ideal_intercept + np.random.normal(size=(num_sample,num_feature))\n",
    "# label=ideal_coef[0]*feature[:,0] + ideal_coef[1]*feature[:,1] + ideal_intercept + np.random.normal(size=(num_sample,))\n",
    "\n",
    "# Slice x into training/testing sets\n",
    "X_train = feature[:-100,:]\n",
    "X_test = feature[-100:,:]\n",
    "# Slice y into training/testing sets\n",
    "y_train = label[:-100]\n",
    "y_test = label[-100:]\n",
    "\n",
    "# fit model\n",
    "model = lm()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict=model.predict(X_test)\n",
    "print(\"mean_square_error:%.2f\" %mean_squared_error(y_test,y_predict))\n",
    "print('R-squared: %.2f' %r2_score(y_test, y_predict))\n",
    "# print('R-squared: %.2f' %model.score(X_test, y_test)) 结果同上\n",
    "print(\"coefficient of the model:%.2f\" %model.coef_)\n",
    "print(\"intercept of the model:%.2f\" %model.intercept_)\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_predict, color='green', linewidth=3)\n",
    "\n",
    "# 残差\n",
    "for idx, x in enumerate(X_test):\n",
    "    plt.plot([x, x], [y_test[idx], y_predict[idx]], 'g-')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_square_error:0.77\n",
      "R-squared: 0.94\n",
      "coefficient of the model:1.99, -3.00\n",
      "intercept of the model:5.01\n",
      "Predicted: -0.07271438265317443, Target: 0.03922225600370047\n",
      "Predicted: 6.280852722825036, Target: 6.253870407864132\n",
      "Predicted: 8.775944063927396, Target: 8.732860121020742\n",
      "Predicted: 5.326408845919238, Target: 4.395374157970787\n",
      "Predicted: -1.5358241412574003, Target: -1.6448838612364678\n",
      "Predicted: 5.275960977034938, Target: 6.001392003019284\n",
      "Predicted: 8.775733480874235, Target: 10.435200692237634\n",
      "Predicted: 6.513261761801678, Target: 5.98029163400112\n",
      "Predicted: 6.050694313711196, Target: 5.8797711056853315\n",
      "Predicted: -0.2569495184380921, Target: -0.5254824982277202\n",
      "Predicted: 10.870493631958324, Target: 9.993172708533809\n",
      "Predicted: 2.731498492313528, Target: 2.2102576941074568\n",
      "Predicted: 0.09600967465724963, Target: 0.9518875623580783\n",
      "Predicted: 6.668971244701007, Target: 8.07321599438161\n",
      "Predicted: 6.063525582840324, Target: 6.120923652956485\n",
      "Predicted: 4.493698770183209, Target: 3.163949181632265\n",
      "Predicted: 2.285889173718714, Target: 2.1840926257805147\n",
      "Predicted: 9.31202584324093, Target: 8.621992348667506\n",
      "Predicted: 0.7912992588033916, Target: 1.7584013643393643\n",
      "Predicted: 6.122528976817175, Target: 7.36154070272766\n",
      "Predicted: 1.9939752129273032, Target: 2.1790381843821898\n",
      "Predicted: 7.794017035215064, Target: 9.5042679557417\n",
      "Predicted: 3.866554689479785, Target: 3.3639139483703424\n",
      "Predicted: 8.612647860189634, Target: 9.160289720068116\n",
      "Predicted: 2.4946620576857885, Target: 1.4775940646683832\n",
      "Predicted: 5.251577366298532, Target: 4.55286284007057\n",
      "Predicted: 5.163567805879629, Target: 4.205177842545179\n",
      "Predicted: 4.086706530641013, Target: 3.3039984228269565\n",
      "Predicted: 5.241934012030339, Target: 4.195808102985081\n",
      "Predicted: 8.511235565090328, Target: 9.733327790576643\n",
      "Predicted: 0.7087941539224936, Target: -0.1520411741767601\n",
      "Predicted: 8.850783940603716, Target: 7.700949992302101\n",
      "Predicted: 3.356087804067995, Target: 3.1837998336677953\n",
      "Predicted: 3.81840392029048, Target: 4.148906638516466\n",
      "Predicted: 8.541315141115913, Target: 7.03575789973071\n",
      "Predicted: 5.772282783218407, Target: 6.50881190289602\n",
      "Predicted: 6.292417514808109, Target: 6.834011491854946\n",
      "Predicted: 6.865676082859027, Target: 7.605890329101951\n",
      "Predicted: 4.780376484408461, Target: 4.2118911345420535\n",
      "Predicted: 11.172474824899034, Target: 11.34225631495629\n",
      "Predicted: 0.9972385621610629, Target: 2.120370386511775\n",
      "Predicted: 11.979923696152486, Target: 13.52251577815976\n",
      "Predicted: 6.056446506394811, Target: 6.496275667042766\n",
      "Predicted: -1.3212009104401936, Target: -0.3642203767091393\n",
      "Predicted: -0.7514648889620155, Target: -0.9431981750958034\n",
      "Predicted: 2.7321304022898465, Target: 2.5253664944942558\n",
      "Predicted: 6.548429664905832, Target: 6.762802638741705\n",
      "Predicted: 7.426974524772758, Target: 8.408224005153558\n",
      "Predicted: 6.659664952423893, Target: 5.917581934269453\n",
      "Predicted: 6.711717882496179, Target: 5.3868878500151975\n",
      "Predicted: 3.272562636126243, Target: 3.6107391340914083\n",
      "Predicted: 2.9453866981877073, Target: 2.4016745655893725\n",
      "Predicted: 5.054428063793857, Target: 4.794431366277009\n",
      "Predicted: 6.739706500864248, Target: 5.641753231065831\n",
      "Predicted: -2.3848958170278802, Target: -3.352021328317279\n",
      "Predicted: -1.2391354435836641, Target: -3.1346922520679823\n",
      "Predicted: 6.844113699666373, Target: 4.978346546931988\n",
      "Predicted: 9.915809653622116, Target: 9.379935690597005\n",
      "Predicted: 8.902651226111036, Target: 8.676765840411448\n",
      "Predicted: 2.5162407754390896, Target: 3.194549315004475\n",
      "Predicted: 1.0012398103684035, Target: -0.3332506706112661\n",
      "Predicted: 0.7740293022705167, Target: 2.3806194358417407\n",
      "Predicted: 8.235133428386666, Target: 7.857239287470232\n",
      "Predicted: 2.9896547733975405, Target: 2.7239829054588656\n",
      "Predicted: 2.9360175891998757, Target: 2.516251843719771\n",
      "Predicted: 1.3777391843554376, Target: 0.6868711006247338\n",
      "Predicted: 4.088338511358857, Target: 1.7495689988838894\n",
      "Predicted: -2.2068409768223054, Target: -2.4314659908577454\n",
      "Predicted: 2.6213327325238662, Target: 3.4764099610511017\n",
      "Predicted: 12.161374629265639, Target: 11.721066298757645\n",
      "Predicted: 9.355504423208265, Target: 10.416585171958417\n",
      "Predicted: 5.959659824996741, Target: 6.0753324729491816\n",
      "Predicted: 9.695387899303018, Target: 8.907339069121472\n",
      "Predicted: 4.4256200008451865, Target: 4.946501904021146\n",
      "Predicted: 8.551711869447768, Target: 8.144026201374357\n",
      "Predicted: 10.716535384045246, Target: 9.48764308407481\n",
      "Predicted: 7.98920949974449, Target: 8.078554035539451\n",
      "Predicted: 5.269233049362928, Target: 5.796920302040634\n",
      "Predicted: 5.163210793257775, Target: 5.675350392254066\n",
      "Predicted: 0.5350716050902289, Target: 0.3430884972365026\n",
      "Predicted: 6.876425848458521, Target: 7.383265345780511\n",
      "Predicted: 7.774099946610954, Target: 7.950263787134667\n",
      "Predicted: 6.205614233600876, Target: 6.136156357543989\n",
      "Predicted: 4.111360242937314, Target: 3.8564191218964603\n",
      "Predicted: 2.8170137416358845, Target: 2.670046638610683\n",
      "Predicted: 2.985195936750332, Target: 3.8884179772109477\n",
      "Predicted: 4.17866970344689, Target: 4.29242129870971\n",
      "Predicted: -1.5626589858127105, Target: -0.6823024943414681\n",
      "Predicted: -1.2845977387497953, Target: -1.1120458230332393\n",
      "Predicted: 4.551852831657967, Target: 5.835834454645122\n",
      "Predicted: 13.287932384664149, Target: 14.382529118871165\n",
      "Predicted: 5.550259587487079, Target: 6.557971197477286\n",
      "Predicted: 8.661779160826079, Target: 9.407428471756925\n",
      "Predicted: 5.567805067668457, Target: 3.9390430260160167\n",
      "Predicted: 4.877119433915024, Target: 4.217020740173742\n",
      "Predicted: 4.488922884015793, Target: 4.519140416663296\n",
      "Predicted: 5.481351294864737, Target: 5.607061033837779\n",
      "Predicted: 2.619268460224046, Target: 1.0570006709926223\n",
      "Predicted: 6.441981329009053, Target: 7.626459955777028\n",
      "Predicted: 6.96664759266547, Target: 6.5169775991608985\n"
     ]
    }
   ],
   "source": [
    "# simple linear regression  二元\n",
    "# !!!!! 注意多元线性回归，feature.reshape(1000,)，一定要统一为二维\n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 定义样本和特征数量\n",
    "num_sample=1000\n",
    "# num_feature = 1\n",
    "num_feature = 2\n",
    "\n",
    "# 生成一些样本和特征\n",
    "# ideal_coef = -3\n",
    "ideal_coef = [2,-3]\n",
    "ideal_intercept = 5\n",
    "feature=np.random.normal(size=(num_sample,num_feature))\n",
    "# label=ideal_coef*feature + ideal_intercept + np.random.normal(size=(num_sample,num_feature))\n",
    "label=ideal_coef[0]*feature[:,0] + ideal_coef[1]*feature[:,1] + ideal_intercept + np.random.normal(size=(num_sample,))\n",
    "\n",
    "# Slice x into training/testing sets\n",
    "X_train = feature[:-100,:]\n",
    "X_test = feature[-100:,:]\n",
    "# Slice y into training/testing sets\n",
    "y_train = label[:-100]\n",
    "y_test = label[-100:]\n",
    "\n",
    "# fit model\n",
    "model = lm()\n",
    "model.fit(X_train,y_train)\n",
    "y_predict=model.predict(X_test)\n",
    "print(\"mean_square_error:%.2f\" %mean_squared_error(y_test,y_predict))\n",
    "print('R-squared: %.2f' %r2_score(y_test, y_predict))\n",
    "# print('R-squared: %.2f' %model.score(X_test, y_test)) 结果同上\n",
    "# print(\"coefficient of the model:%.2f\" %model.coef_)\n",
    "print(\"coefficient of the model:%.2f, %.2f\" %(model.coef_[0],model.coef_[1]))\n",
    "print(\"intercept of the model:%.2f\" %model.intercept_)\n",
    "for i, prediction in enumerate(y_predict):\n",
    "    print('Predicted: %s, Target: %s' % (prediction, y_test[i]))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression & Lasso Regression\n",
    "- 语法：\n",
    "    ```python\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import RidgeCV\n",
    "    from sklearn.linear_model import LassoCV\n",
    "    ```\n",
    "- Parameters:  \n",
    "\n",
    "    **alpha/alphas(CV)**：正则项系数，初始值为1，数值越大，则对复杂模型的惩罚力度越大。 \n",
    "    **cv**： cross-validation generator，默认留一。  \n",
    "    **random_state**：种子相同，可以复现。\n",
    "    **max_iter**：最大迭代次数。  \n",
    "    **fit_intercept**：有无截距  \n",
    "    **copy_X**：True赋值，False覆写  \n",
    "    **normalize**：是否归一化  \n",
    "    **n_jobs**：default=1，使用CPU数，-1为使用所有CPU  \n",
    "\n",
    "    更多参数见 [sklearn线性回归参数](https://blog.csdn.net/VariableX/article/details/107166602)\n",
    "\n",
    "- 调参方法：  \n",
    "\n",
    "  1. 给定alpha较小的值，例如0.1。\n",
    "  2. 根据验证集准确率以10倍为单位增大或者减小参数值。[0.001, 0.01, 0.1, 1, 10, 100]\n",
    "  3. 在找到合适的数量级后，在此数量级上微调。  \n",
    "    <br>\n",
    "- Attributes (CV)  \n",
    "    **alpha_**  \n",
    "    **best_score_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_square_error:1.04\n",
      "R-squared: 0.92\n",
      "coefficient of the model:2.04, -3.01\n",
      "intercept of the model:5.01\n",
      "best alpha:0.10\n",
      "best score:-1.06\n",
      "Predicted: 6.172865151236799, Target: 5.221032000671414\n",
      "Predicted: 3.0948569367324072, Target: 3.0553416566442486\n",
      "Predicted: 10.119495611142352, Target: 9.35878020901792\n",
      "Predicted: 6.650222238623546, Target: 7.531043584329374\n",
      "Predicted: 4.396544569092065, Target: 5.972177034184012\n",
      "Predicted: 3.904422019614505, Target: 4.26300079519759\n",
      "Predicted: 6.108400415625479, Target: 6.26761967522712\n",
      "Predicted: 9.98326118553673, Target: 8.871682061968292\n",
      "Predicted: 3.7561999405194992, Target: 1.136879301682896\n",
      "Predicted: -0.17605344571861714, Target: -0.5889758863189452\n",
      "Predicted: -0.20929468309352295, Target: 0.6078249192895236\n",
      "Predicted: 0.593354401071843, Target: 0.7696330467050877\n",
      "Predicted: 10.365149646405165, Target: 11.046063758161269\n",
      "Predicted: 3.2208820469149377, Target: 2.8507592834207345\n",
      "Predicted: 6.28428243973401, Target: 6.495823133728423\n",
      "Predicted: 3.5639293543212665, Target: 2.392516898619788\n",
      "Predicted: 9.383855522206051, Target: 9.000505766544904\n",
      "Predicted: 5.945957792448008, Target: 6.462067611425758\n",
      "Predicted: 8.1449116621653, Target: 9.733165793139635\n",
      "Predicted: 7.983423610860328, Target: 8.349655250140215\n",
      "Predicted: 1.2416414054889766, Target: 1.1837322001884834\n",
      "Predicted: 7.98504291414257, Target: 7.560209935980627\n",
      "Predicted: 13.020284022528804, Target: 11.429742369057566\n",
      "Predicted: 7.052102788024115, Target: 5.680104547019259\n",
      "Predicted: 11.364427680464066, Target: 9.422250988408035\n",
      "Predicted: 5.285317376339491, Target: 6.497887377688539\n",
      "Predicted: 12.368408441895843, Target: 13.170387382659602\n",
      "Predicted: 0.36262103631379006, Target: -1.5363975468182305\n",
      "Predicted: 5.435655569910706, Target: 5.44672148966259\n",
      "Predicted: 7.389070673917484, Target: 7.641843555895382\n",
      "Predicted: 6.239848960256099, Target: 6.332514017856013\n",
      "Predicted: 4.960646876789948, Target: 5.2673202425339\n",
      "Predicted: 5.405321943223347, Target: 4.330585305110994\n",
      "Predicted: 4.873434146064797, Target: 5.545941515386761\n",
      "Predicted: 4.40555474415606, Target: 4.448218547954941\n",
      "Predicted: 7.920086918896517, Target: 7.431923673646523\n",
      "Predicted: 2.8450300779131794, Target: 1.6384803490362103\n",
      "Predicted: 4.308779357007824, Target: 4.640190554367108\n",
      "Predicted: 0.5551152139817113, Target: 0.01021129180731739\n",
      "Predicted: 5.527071438478264, Target: 5.666508177698069\n",
      "Predicted: 2.014427642911812, Target: 2.204872406157825\n",
      "Predicted: 10.038099220371548, Target: 10.154754953616532\n",
      "Predicted: 6.966107307912157, Target: 4.984568046723189\n",
      "Predicted: 5.6003178754489555, Target: 5.631405356516281\n",
      "Predicted: -0.09635003562361799, Target: 0.6323611078527688\n",
      "Predicted: 10.640075921894255, Target: 10.494155409279168\n",
      "Predicted: 2.80353291045959, Target: 4.782455678259481\n",
      "Predicted: 8.231642778147654, Target: 9.242402950501114\n",
      "Predicted: 6.026701907692578, Target: 6.314098836919643\n",
      "Predicted: 6.045355727142319, Target: 6.668860734106761\n",
      "Predicted: 1.8465786865813718, Target: 2.7041486153350527\n",
      "Predicted: 3.0742514413521085, Target: 3.4810866486422376\n",
      "Predicted: 5.5193173172742656, Target: 4.555693959744041\n",
      "Predicted: 1.866632354668869, Target: 2.1335414157247885\n",
      "Predicted: -0.12655091182126554, Target: -1.1549119979312057\n",
      "Predicted: 5.201122860986721, Target: 5.124143751388735\n",
      "Predicted: 4.578624090267029, Target: 4.791286678138382\n",
      "Predicted: 9.131502170908677, Target: 8.734668641278633\n",
      "Predicted: 0.09569395333712638, Target: -0.9818969043388799\n",
      "Predicted: 0.7910865181715394, Target: -0.7375929968956789\n",
      "Predicted: -0.0010638932410280688, Target: -0.07864845125080715\n",
      "Predicted: 8.020842721645904, Target: 8.23979498686914\n",
      "Predicted: 8.339066842952938, Target: 7.411425026628751\n",
      "Predicted: 9.138795548044676, Target: 11.813082435986798\n",
      "Predicted: 4.096700795530099, Target: 4.718658809550847\n",
      "Predicted: 8.125507473568192, Target: 8.095413101130553\n",
      "Predicted: 0.6954385015004085, Target: -1.4996377489164914\n",
      "Predicted: 9.568823730659131, Target: 9.230813842256651\n",
      "Predicted: 9.777884853815252, Target: 10.743754456788103\n",
      "Predicted: 1.1319394565744463, Target: 0.7269762339015349\n",
      "Predicted: 1.5830797509969097, Target: 1.855370681626738\n",
      "Predicted: 8.69572398911026, Target: 9.284345701589528\n",
      "Predicted: 4.473628927047861, Target: 6.130470896827526\n",
      "Predicted: 1.175961249462818, Target: 3.1721571273025564\n",
      "Predicted: 1.9043852126951375, Target: 3.023030466683071\n",
      "Predicted: 7.47342120077116, Target: 6.737210412376276\n",
      "Predicted: 5.717423730048683, Target: 6.668827988731559\n",
      "Predicted: 8.971518599682923, Target: 10.083291058264251\n",
      "Predicted: 2.429981641969718, Target: 2.397066209520533\n",
      "Predicted: 3.330236096031932, Target: 3.0963298727879773\n",
      "Predicted: 6.313821518258246, Target: 5.515076336555641\n",
      "Predicted: 2.77098514944184, Target: 1.8172604920453992\n",
      "Predicted: 0.7008791495973323, Target: 1.3827042572296926\n",
      "Predicted: 1.9136068663198378, Target: 0.8960702186337399\n",
      "Predicted: 11.48904284435024, Target: 11.211253263205945\n",
      "Predicted: 5.5915346142344475, Target: 5.81416262477553\n",
      "Predicted: 6.938007681476183, Target: 5.247363208491605\n",
      "Predicted: 1.6005208861019549, Target: 0.9924224026596595\n",
      "Predicted: -2.7606757301083613, Target: -2.87060771071795\n",
      "Predicted: 1.9756893930748896, Target: -0.12217345051520079\n",
      "Predicted: 10.17176814597906, Target: 10.295119669353785\n",
      "Predicted: 1.8864001604197682, Target: 2.7885463351237534\n",
      "Predicted: 4.901687881556956, Target: 7.544827928184834\n",
      "Predicted: 4.679447621542748, Target: 5.720957786676357\n",
      "Predicted: 2.784030929594176, Target: 2.2475830074988035\n",
      "Predicted: 5.609365072340395, Target: 5.626914570199657\n",
      "Predicted: 1.0592806040139324, Target: 0.6999197352896782\n",
      "Predicted: 10.492029966870343, Target: 11.806253626790337\n",
      "Predicted: -2.0169906279255603, Target: -0.3969731793903457\n",
      "Predicted: 7.6687019740707045, Target: 8.319320587891237\n"
     ]
    }
   ],
   "source": [
    "# RidgeCV\n",
    "from sklearn.linear_model import RidgeCV as lm\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 定义样本和特征数量\n",
    "num_sample=1000\n",
    "# num_feature = 1\n",
    "num_feature = 2\n",
    "\n",
    "# 生成一些样本和特征\n",
    "# ideal_coef = -3\n",
    "ideal_coef = [2,-3]\n",
    "ideal_intercept = 5\n",
    "feature=np.random.normal(size=(num_sample,num_feature))\n",
    "# label=ideal_coef*feature + ideal_intercept + np.random.normal(size=(num_sample,num_feature))\n",
    "label=ideal_coef[0]*feature[:,0] + ideal_coef[1]*feature[:,1] + ideal_intercept + np.random.normal(size=(num_sample,))\n",
    "\n",
    "# Slice x into training/testing sets\n",
    "X_train = feature[:-100,:]\n",
    "X_test = feature[-100:,:]\n",
    "# Slice y into training/testing sets\n",
    "y_train = label[:-100]\n",
    "y_test = label[-100:]\n",
    "\n",
    "# fit model\n",
    "model = lm(alphas = [0.01,0.1,1,10,100])\n",
    "model.fit(X_train,y_train)\n",
    "y_predict=model.predict(X_test)\n",
    "print(\"mean_square_error:%.2f\" %mean_squared_error(y_test,y_predict))\n",
    "print('R-squared: %.2f' %r2_score(y_test, y_predict))\n",
    "# print('R-squared: %.2f' %model.score(X_test, y_test)) 结果同上\n",
    "# print(\"coefficient of the model:%.2f\" %model.coef_)\n",
    "print(\"coefficient of the model:%.2f, %.2f\" %(model.coef_[0],model.coef_[1]))\n",
    "print(\"intercept of the model:%.2f\" %model.intercept_)\n",
    "print(\"best alpha:%.2f\" %model.alpha_)\n",
    "print(\"best score:%.2f\" %model.best_score_)\n",
    "for i, prediction in enumerate(y_predict):\n",
    "    print('Predicted: %s, Target: %s' % (prediction, y_test[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Elastic Net 弹性网\n",
    "##### Perceptron 感知机"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非线性\n",
    "\n",
    "- 线性模型解决非线性问题\n",
    "  - 分箱\n",
    "  - 多项式回归\n",
    "- Decision tree\n",
    "- Random forest\n",
    "- SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性模型-分箱\n",
    "\n",
    "- 语法：\n",
    "    ```python\n",
    "    from sklearn.preprocessing import KBinsDiscretizer\n",
    "    ```\n",
    "- Parameters:  \n",
    "\n",
    "    **n_bins**：几个箱子  \n",
    "    **strategy**：{‘uniform’, ‘quantile’, ‘kmeans’}，default=’quantile’，宽度一样，点数一样，kmeans聚类\n",
    "    **random_state**：种子相同，可以复现。  \n",
    "\n",
    "- Attributes:  \n",
    "\n",
    "    **bin_edges_**：边界array  \n",
    "    **n_bins_**：个数int array  \n",
    "    **n_features_in_**  \n",
    "    **feature_names_in_**  \n",
    "\n",
    "- Methods:\n",
    "\n",
    "    **fit(X)**  \n",
    "    **transform(X)**  \n",
    "    **inverse_transform(Xt)**  \n",
    "    **fit_transform(X, y)**  \n",
    "    **get_params(X, y, sample_weight)**: 获取参数  \n",
    "    **set_params(para)**: 设置参数    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 线性模型-多项式拟合\n",
    "\n",
    "- 语法：\n",
    "    ```python\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    quadratic_featurizer = PolynomialFeatures(degree=2)\n",
    "    X_train_quadratic = quadratic_featurizer.fit_transform(X_train)\n",
    "    X_test_quadratic = quadratic_featurizer.fit_transform(X_test)\n",
    "    ```\n",
    "- Parameters:  \n",
    "\n",
    "    **degree**：几次  \n",
    "    **random_state**：种子相同，可以复现。  \n",
    "\n",
    "- Attributes:  \n",
    "\n",
    "    **powers_**：各个项分别是几次  \n",
    "    **n_output_features_**：多项式升维后有几个feature  \n",
    "    **n_features_in_**：升维前有几个feature  \n",
    "    **feature_names_in_**：升维前feature名字  \n",
    "\n",
    "- Methods:\n",
    "\n",
    "    **fit(X)**  \n",
    "    **fit_transform(X,y)**\n",
    "    **get_params(X, y, sample_weight)**: 获取参数  \n",
    "    **set_params(para)**: 设置参数 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decision Tree\n",
    "[决策树详讲](https://ml.bbbdata.com/site/text/32)\n",
    "- 优点\n",
    "  - 不用标准化，归一化\n",
    "  - 可以同时处理连续变量和离散变量。其他的工具常常只能分析一种变量。\n",
    "  - 运算速度快。训练决策树的成本和数据点的数量为对数关系。\n",
    "  - 利于理解和解释，便于可视化。\n",
    "  - 统计检验可检验模型可靠性。  \n",
    "\n",
    "- 缺点\n",
    "  - 容易过拟合\n",
    "  - 不稳定\n",
    "  - 局部最优\n",
    "  - 每个类别的样本量要平衡（样本数大于特征数）  \n",
    "\n",
    "- 三种算法对比\n",
    "  - 适用范围  \n",
    "    ID3算法只能处理离散特征的分类问题，C4.5能够处理离散特征和连续特征的分类问题，CART算法可以处理离散和连续特征的分类与回归问题。  \n",
    "  - 假设空间：  \n",
    "    ID3和C4.5算法使用的决策树可以是多分叉的，而CART算法的决策树必须是二叉树。\n",
    "  - 优化算法：  \n",
    "    ID3算法没有剪枝策略，当叶子节点上的样本都属于同一个类别或者所有特征都使用过了的情况下决策树停止生长。  \n",
    "    C4.5算法使用预剪枝策略，当分裂后的增益小于给定阈值或者叶子上的样本数量小于某个阈值或者叶子节点数量达到限定值或者树的深度达到限定值，决策树停止生长。  \n",
    "    CART决策树主要使用后剪枝策略。  \n",
    "- 语法\n",
    "  ```python\n",
    "  from sklearn.tree import DecisionTreeRegressor\n",
    "  ```\n",
    "- Parameters（主要看前2/3，最多看前5）  \n",
    "  \n",
    "  **max_leaf_nodes**： 通过限制最大叶子节点数，可以防止过拟合，默认是\"None”，即不限制最大的叶子节点数。如果加了限制，算法会建立在最大叶子节点数内最优的决策树。如果特征不多，可以不考虑这个值，但是如果特征分成多的话，可以加以限制具体的值可以通过交叉验证得到。  \n",
    "\n",
    "  **max_depth**：int or None, optional (default=None) 一般来说，数据少或者特征少的时候可以不管这个值。如果模型样本量多，特征也多的情况下，推荐限制这个最大深度，具体的取值取决于数据的分布。常用的可以取值10-100之间。常用来解决过拟合。  \n",
    "\n",
    "  **ccp_alpha**：剪枝时的alpha系数，需要剪枝时设置该参数，默认值是不会剪枝的。  \n",
    "\n",
    "  **min_samples_split**：如果某节点的样本数少于min_samples_split，则不会继续再尝试选择最优特征来进行划分，如果样本量不大，不需要管这个值。如果样本量数量级非常大，则推荐增大这个值。  \n",
    "\n",
    "  **min_samples_leaf**： 这个值限制了叶子节点最少的样本数，如果某叶子节点数目小于样本数，则会和兄弟节点一起被剪枝，如果样本量不大，不需要管这个值，大些如10W可以尝试下5  \n",
    "\n",
    "  **random_state**：种子相同，可以复现。  \n",
    "  \n",
    "  **criterion**：（回归树）mse:默认，均方差，mae：平均绝对差，friedman_mse。（分类树）gini或者entropy,前者是基尼系数，后者是信息熵。两种算法差异不大对准确率无影响，信息熵运算效率低一点，因为它有对数运算.一般说使用默认的基尼系数”gini”就可以了，即CART算法。除非你更喜欢类似ID3, C4.5的最优特征选择方法。  \n",
    "\n",
    "  **splitter**：best or random 前者是在所有特征中找最好的切分点，后者是在部分特征中。默认的”best”适合样本量不大的时候，而如果样本数据量非常大，推荐”random” 。  \n",
    "\n",
    "  **max_features**：None（所有），log2，sqrt，N  特征小于50的时候一般使用所有的。  \n",
    "\n",
    "  **min_weight_fraction_leaf**： 这个值限制了叶子节点所有样本权重和的最小值，如果小于这个值，则会和兄弟节点一起被剪枝默认是0，就是不考虑权重问题。一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引入样本权重，这时我们就要注意这个值了。    \n",
    "\n",
    "  **class_weight**： 指定样本各类别的的权重，主要是为了防止训练集某些类别的样本过多导致训练的决策树过于偏向这些类别。这里可以自己指定各个样本的权重，如果使用“balanced”，则算法会自己计算权重，样本量少的类别所对应的样本权重会高。（分类树有，回归树无）  \n",
    "\n",
    "  **min_impurity_split**： 这个值限制了决策树的增长，如果某节点的不纯度(基尼系数，信息增益，均方差，绝对差)小于这个阈值则该节点不再生成子节点。即为叶子节点 。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification -- discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X1 = np.arange(1, 9).reshape(-1, 2)\n",
    "X2 = np.arange(10, 14).reshape(-1, 2)\n",
    "y = np.arange(2, 4).reshape(-1, 1)\n",
    "X1\n",
    "X2\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  2.,  1.,  2.,  4.],\n",
       "       [ 1.,  3.,  4.,  9., 12., 16.],\n",
       "       [ 1.,  5.,  6., 25., 30., 36.],\n",
       "       [ 1.,  7.,  8., 49., 56., 64.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_binned = poly.fit_transform(X1)\n",
    "X_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,  10.,  11., 100., 110., 121.],\n",
       "       [  1.,  12.,  13., 144., 156., 169.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_binned = poly.transform(X2)\n",
    "line_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [2, 0],\n",
       "       [1, 1],\n",
       "       [0, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly.powers_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
